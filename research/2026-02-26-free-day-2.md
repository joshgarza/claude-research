---
date: 2026-02-26
topic: Free day — Optimal Stopping Theory and the 37% Rule
status: complete
tags: [mathematics, decision-theory, algorithms, probability, philosophy]
related: [2026-02-26-free-day.md]
---

# Optimal Stopping Theory: The Mathematics of "When to Stop Looking"

## Context

Free day research (second session for 2026-02-26; the first covered Conway's Game of Life). I chose optimal stopping theory because it answers one of the most universal human questions — *when do you stop searching and commit?* — with a provably optimal algorithm that reduces to one surprising number: **37%**.

This connects pure mathematics (probability theory, dynamic programming, martingale theory) to everyday decisions (apartment hunting, job offers, dating, parking) and reaches into computer science (online algorithms, multi-armed bandits, competitive analysis, prophet inequalities). It's one of the rare fields where a mathematical result is both genuinely profound and actionable in real life.

---

## Findings

### The Problem

Imagine you're hiring a secretary. There are *n* applicants, interviewed one by one in a random order. After each interview you can observe only the **relative rank** of the current candidate compared to all seen so far — not their absolute quality. You must decide immediately after each interview: hire them now, or reject them forever. Once rejected, a candidate cannot be recalled.

**Goal**: maximize the probability of hiring the *best* candidate overall.

This is the **secretary problem**, also called the marriage problem, sultan's dowry problem, fussy suitor problem, and best choice problem. It is the foundational problem of optimal stopping theory.

The problem is deceptively hard to reason about intuitively. You can't interview everyone and pick the best (no going back). You can't set an absolute quality threshold (you only know relative ranks). You're making irreversible sequential decisions under uncertainty.

### The 37% Rule

The solution is a **threshold strategy**: observe the first *r − 1* applicants without hiring anyone (the **look phase**), then hire the **first subsequent candidate who is better than everyone seen so far** (the **leap phase**). If no one in the leap phase beats the look phase's best, you're stuck with the last candidate.

The optimal threshold *r* is:

```
r* = ⌊n/e⌋ ≈ 0.368n ≈ 37% of n
```

where *e* ≈ 2.71828 is Euler's number. The probability of success **converges to 1/e ≈ 36.8%** as n grows — and this is the *best possible* success probability for this problem structure.

The rule is **scale-invariant**: it doesn't matter whether you have 100 or 100 million applicants. Observe the first 37%, then take the next one who beats everything you've seen.

**Empirical validation** (1 million simulations, [Ozioma Ogbe](https://blog.oziomaogbe.com/2022/01/09/secretary-problem-experiment.html)): With 100 applicants, peak success occurred at 36% threshold (371,238 wins/million). With 1,000 applicants, peak occurred at exactly 37% (369,144 wins/million). Theory confirmed.

### Mathematical Proof Sketch

The proof uses **backward induction**. For a threshold *r*, you hire the first candidate after position *r* who is a **running maximum** (better than all prior candidates). The probability that candidate *k* (for *k > r*) is the absolute best AND is the first running maximum after position *r* is:

```
P(win at position k) = (r / (k − 1)) × (1/n)
```

The first factor: the best among the first *(k − 1)* candidates must be in the look phase (so candidate *k* is a running maximum). The second factor: candidate *k* must be actually best overall.

Sum over k from *r+1* to *n*:

```
P(r, n) = (r/n) × Σ(k=r+1 to n) [1 / (k − 1)]
         ≈ (r/n) × ln(n/r)    [continuous limit]
```

Maximize over *t = r/n*: differentiate *t × ln(1/t)* with respect to *t*, set to zero:

```
d/dt [t × ln(1/t)] = ln(1/t) - 1 = 0
→ t = 1/e ≈ 0.368
```

The maximum value is also *1/e*. So both the **optimal threshold** and the **success probability** are 1/e.

([Source: Suri UCSB lecture notes](https://sites.cs.ucsb.edu/~suri/ccs130a/OptStopping.pdf))

### History

The field evolved slowly across a century:

- **1875 — Arthur Cayley** (Cambridge): first known optimal stopping problem — sequential purchase of lottery tickets. Used backward induction, the same technique underpinning all modern solutions. ([hill.math.gatech.edu](https://hill.math.gatech.edu/publications/PAPER%20PDFS/AmSciKnowingWhenToStop_Online2009.pdf))

- **1940s — World War II / Abraham Wald**: Wald developed **sequential analysis** (testing hypotheses while collecting data, stopping when evidence is sufficient) for wartime quality control. This is optimal stopping applied to hypothesis testing.

- **1949–1958 — Merrill Flood**: first formulated the secretary problem in its modern form. The problem circulated in the oral tradition before formal publication. Flood attributed the discovery to 1949.

- **1961 — D.V. Lindley**: rigorous decision-theoretic analysis.

- **1963 — E.B. Dynkin**: formalized the mathematical structure using martingale theory.

- **1966 — Gilbert and Mosteller** (Harvard): landmark paper. Proved the 37-card threshold, analyzed the full-information variant, and established much of the problem's modern structure.

- **1979 — John Gittins**: introduced the **Gittins Index** for multi-armed bandit problems, generalizing the exploration/exploitation tradeoff that optimal stopping captures. Proved optimal policy for discounted infinite-horizon bandits. ([statslab.cam.ac.uk](https://www.statslab.cam.ac.uk/~rrw1/oc/ocgittins.pdf))

- **1978 — Krengel and Sucheston**: proved the **prophet inequality** — that an optimal sequential policy achieves at least half the expected value of an omniscient prophet. Foundation of modern algorithmic mechanism design.

- **2000 — F.T. Bruss**: introduced the **Odds Algorithm** (Bruss algorithm), providing an elegant O(n) computation of the optimal stopping threshold, unifying many variants. ([arxiv:1212.1391](https://arxiv.org/pdf/1212.1391))

### The Odds Algorithm

Bruss's 2000 result is particularly elegant. Frame the problem in terms of "relative records" (candidates who are best so far). Define the **odds** of candidate *i* being a relative record as *q_i / p_i* where *p_i* is the probability of being a record.

The algorithm: sum odds from the *end* of the sequence backwards until the sum hits or exceeds 1. The optimal stopping threshold is the start of that final segment. This formulation:
- Works for **unknown n** (random number of candidates)
- Handles **non-uniform probabilities** per position
- Runs in **O(n) time** without dynamic programming
- Recovers the classic 37% rule as a special case

### Key Variants

The secretary problem is actually a family of related problems. Changing one assumption can dramatically shift the optimal strategy.

#### Full-Information Problem (Moser 1956, Gilbert-Mosteller 1966)
What if candidates have known absolute values (drawn i.i.d. from a known distribution)? Now you can use a **threshold rule**: set a value threshold and accept the first candidate who exceeds it, lowering the threshold over time as remaining candidates dwindle. This outperforms the relative-ranking version — cardinal information is worth a lot.

#### Candidates Can Reject You
If selected candidates reject you with 50% probability, the optimal look phase shrinks to **25%** (not 37%). With **recall allowed** (50% probability of success when going back to someone previously passed over), the optimal look phase jumps to **61%**, achieving ~61% success. The ability to go back to prior candidates is extremely valuable. ([tosummarise.com](https://www.tosummarise.com/optimal-stopping-from-algorithms-to-live-by/))

#### Multiple Secretaries
If you can select *k* candidates (not just one), the look phase shortens and success probability per choice improves. With *k=2*, the optimal threshold drops below 37%.

#### The Parking Problem
Drive toward a destination; spots appear randomly. Each spot must be accepted or skipped. Optimal strategy: drive past all spots beyond a threshold distance, then take the first available spot inside the threshold. The threshold boundary is set by the expected density of available spots.

#### The House-Selling Problem
You're selling a house. Buyers arrive with offers from a known distribution. Each offer expires. Unlike the pure secretary problem, you care about offer *magnitude*, not just whether it's the best. When there are **holding costs** (mortgage while waiting), the optimal strategy is a **reservation price** — accept the first offer exceeding it. The reservation price is stationary in infinite-horizon discounted versions (analyzed via Bellman equations). ([UCLA Stopping textbook](https://www.math.ucla.edu/~tom/Stopping/Contents.html))

#### Bandit Problems and Gittins Index
The bandit problem generalizes optimal stopping to multiple options with unlimited time. The **Gittins Index Theorem** (1979) proves that the optimal policy for discounted rewards is to always choose the arm with the highest Gittins index — a quantity computable independently for each arm via an optimal stopping subproblem. This directly connects optimal stopping theory to reinforcement learning's exploration-exploitation tradeoff. ([Gittins index — Wikipedia](https://en.wikipedia.org/wiki/Gittins_index))

### The Prophet Inequality

A stunning 1978 result (Krengel and Sucheston): suppose a **prophet** can look into the future and always pick the highest-value option. What's the best an **ordinary decision-maker** (who must decide sequentially) can achieve relative to the prophet?

Answer: **at least half the prophet's expected value** — a competitive ratio of 1/2. Furthermore, this is achievable with a **simple threshold rule**: compute a single value *T* such that Pr[max(values) > T] = 1/2, then accept the first value exceeding *T*. No complex dynamic programming needed.

This is the foundation of modern **algorithmic mechanism design** and **posted-price auctions**. The insight that a simple threshold achieves half the omniscient optimum is used in online advertising, e-commerce dynamic pricing, and cloud resource allocation. Recent work (2020s) extends prophet inequalities to multi-item and correlated settings. ([Prophet inequality — Wikipedia](https://en.wikipedia.org/wiki/Prophet_inequality))

### Computer Science: Online Algorithms

In theoretical CS, optimal stopping is a special case of **online algorithms** — algorithms making decisions without seeing future input.

The **ski rental problem** is the canonical introductory case: skiing for an unknown number of days; renting = $1/day, buying = $10. Optimal deterministic strategy: rent for 9 days, buy on day 10 if still skiing. Competitive ratio: 2 (never more than 2× the offline optimal). A randomized algorithm achieves ratio ~1.58. ([Ski rental — Wikipedia](https://en.wikipedia.org/wiki/Ski_rental_problem))

The broader theory of **competitive analysis** quantifies the worst-case ratio between online and offline algorithms. Optimal stopping gives the framework; competitive ratio measures the gap.

Secretary problem variants in algorithms:
- **Online matching** (bipartite graph arriving sequentially)
- **Online knapsack** (items with a capacity constraint)
- **Adwords problem** (Google's keyword auction, analyzed by Mehta et al. 2007 as an optimal stopping variant)

### Practical Applications

#### Dating
The most famous application. Dating from age 18 to 40, the 37% rule says: explore until **age 26.1**, then commit to the first partner who exceeds everyone seen. Real violations: unknown pool size, recall is possible, partial information rather than pure rankings, you can be rejected. But the framework provides a useful mental model: **distinguish exploration from exploitation phases explicitly**. ([bigthink.com](https://bigthink.com/neuropsych/the-37-percent-rule/))

#### Apartment Hunting
Cleanest real-world fit. Deadline exists, apartments must be committed to on the spot, and you can estimate how many you'll see. Rule: spend the first 37% of your search budget observing without committing (learn the market), then take the first apartment that beats everything seen. ([operations-research-bit/medium](https://medium.com/operations-research-bit/the-application-of-optimal-stopping-theory-for-finding-a-rental-apartment-6de84e7ae0b7))

#### Salary Negotiation
Use early offers to calibrate the market, then accept the first offer that beats your calibrated benchmark. The look phase is the first 37% of companies you'd realistically interview with.

#### Parking
Drive past all spots beyond a threshold distance from destination; take the first available spot inside the threshold. Threshold set by parking density and walking speed tradeoff.

#### Jeff Bezos's Regret Minimization Framework
Bezos's "project yourself to age 80 and ask what you'd regret" is a folk version of optimal stopping: don't let fear of missing a future option prevent you from taking a good current option, but don't stop your search too early to relieve anxiety. The key insight is shared: **explicit phase transition from exploration to exploitation**. ([Inc.com](https://www.inc.com/jessica-stillman/jeff-bezos-this-is-how-to-avoid-regret.html))

#### Machine Learning
Optimal stopping underpins:
- **Early stopping** in neural network training (stop when validation loss stops improving)
- **Hyperparameter search** duration
- **Contextual bandits** in recommendation systems (Gittins-index-based exploration)
- **Monte Carlo Tree Search stopping** in game AI

### Failure Modes and Limitations

The 37% rule is provably optimal *within its assumptions*. Those assumptions fail often.

**1. Unknown n**
Classic formulation requires knowing total candidates in advance. In dating, this is unknowable. Partial fix: use a time-based threshold (explore for a fixed period) or estimate *n* from base rates.

**2. No recall**
Real life often allows going back. As shown above, 50% recall probability pushes the optimal threshold to 61% — a dramatically different strategy.

**3. Relative ranking only**
Real decisions involve absolute values. If all candidates in the current market are poor, you might rationally wait rather than commit. The full-information variant (cardinal values) dominates when such information is available.

**4. Non-random ordering**
Real candidate pools are correlated and non-random. Good candidates often cluster (apply in similar windows, come from similar sources).

**5. Empirically, humans stop too early**
Research finds people stop *before* the 37% threshold. Anxiety, social pressure, and availability bias systematically induce under-exploration. The 37% rule is corrective: **it tells most people to keep looking longer, not shorter**. ([IFLScience](https://www.iflscience.com/math-says-you-should-use-the-37-percent-rule-for-big-life-decisions-78618))

**6. 37% success is cold comfort**
Even with optimal play, you fail 63% of the time. For high-stakes irreversible decisions, this may be insufficient — which is where recall, cardinal information, or relaxed criteria (e.g., "top 5%" not "the single best") become important.

### The Deeper Lesson: Look Then Leap

Beyond the specific algorithm, optimal stopping theory articulates a fundamental structure:

1. **Explore before exploiting.** Pure "take the first good thing you see" fails (no calibration). Pure "keep looking" fails (time runs out). The optimal strategy has a defined exploration phase followed by a defined exploitation phase.

2. **Commit fully once the threshold is crossed.** Hesitating after the threshold is suboptimal — you've gathered enough information; acting on it is the correct move.

3. **The value of information decays.** Early candidates teach you a lot about the distribution. Late candidates teach you less. The optimal threshold captures exactly when the marginal information value of another candidate drops below the cost of not yet having committed.

4. **Regret is asymmetric.** Missing the best option *while in the look phase* is survivable (you can still find a running maximum in the leap phase). Failing to commit to a great candidate *in the leap phase* is what kills performance. This is why the algorithm says "take the first person who beats your benchmark" — waiting for even better after crossing the threshold is a mistake.

---

## Open Questions

- **Continuous-time optimal stopping**: In finance, this is the theory of American options (exercise now or wait?). The Snell envelope and Hamilton-Jacobi-Bellman equations describe the continuous limit. How well does the discrete 37% intuition translate?

- **Correlated candidates**: Real search problems have correlated candidates (interview loops, neighborhood effects in apartment hunting). What happens to the optimal threshold when candidates are not independent?

- **Multi-criteria optimal stopping**: The secretary problem optimizes a single criterion (best overall). Real decisions involve multiple incommensurable criteria. Is there a tractable extension for Pareto-optimal stopping?

- **Optimal stopping for AI agents**: When should an agent stop searching for a better plan/solution and commit to execution? The look-then-leap framework seems directly applicable to agent decision loops — especially for research tasks, code exploration, and tool selection.

- **Adversarial ordering**: If candidates arrive in adversarial order (not random), competitive analysis gives bounds but typically much worse than 37%. How does adversarial ordering interact with real-world search environments?

---

## Extracted Principles

No new principles file created — this is exploratory research with connections to general decision-making rather than the software engineering contexts this project focuses on. However, the look-then-leap structure is a meta-pattern that recurs throughout engineering:

- A/B test duration planning (don't peek too early; commit to a predetermined observation window)
- Hiring pipelines (define a calibration phase before making offers)
- Technology selection (evaluate options in parallel up to a deadline, then commit)
- Early stopping in ML training
- Agent tool selection (explore tool combinations before committing to an approach)

If decision-theory content becomes more central to this project, a `principles/decision-theory.md` would be worth creating.

---

**Sources**

- [Secretary problem — Wikipedia](https://en.wikipedia.org/wiki/Secretary_problem)
- [Optimal stopping — Wikipedia](https://en.wikipedia.org/wiki/Optimal_stopping)
- [Odds algorithm (Bruss algorithm) — Wikipedia](https://en.wikipedia.org/wiki/Bruss_algorithm)
- [Prophet inequality — Wikipedia](https://en.wikipedia.org/wiki/Prophet_inequality)
- [Gittins index — Wikipedia](https://en.wikipedia.org/wiki/Gittins_index)
- [Ski rental problem — Wikipedia](https://en.wikipedia.org/wiki/Ski_rental_problem)
- [Optimal Stopping and Applications — T.S. Ferguson (UCLA)](https://www.math.ucla.edu/~tom/Stopping/Contents.html)
- [Knowing When to Stop — American Scientist / hill.math.gatech.edu](https://hill.math.gatech.edu/publications/PAPER%20PDFS/AmSciKnowingWhenToStop_Online2009.pdf)
- [Empirical test of the 37% rule — Ozioma Ogbe](https://blog.oziomaogbe.com/2022/01/09/secretary-problem-experiment.html)
- [Optimal stopping from Algorithms to Live By — To Summarise](https://www.tosummarise.com/optimal-stopping-from-algorithms-to-live-by/)
- [The 37% rule — MathsIsFun](https://www.mathsisfun.com/numbers/optimal-stopping.html)
- [The Regret Minimization Framework — Bezos/Inc.com](https://www.inc.com/jessica-stillman/jeff-bezos-this-is-how-to-avoid-regret.html)
- [New Developments of the Odds Theorem — Bruss (arxiv)](https://arxiv.org/pdf/1212.1391)
- [Optimal Stopping Rules — Suri (UCSB lecture notes)](https://sites.cs.ucsb.edu/~suri/ccs130a/OptStopping.pdf)
- [Algorithms to Live By — algorithmstoliveby.com](https://algorithmstoliveby.com/excerpt.html)
- [The 37% Rule empirical criticisms — IFLScience](https://www.iflscience.com/math-says-you-should-use-the-37-percent-rule-for-big-life-decisions-78618)
- [Multi-Armed Bandits and Gittins Index — Weber (Cambridge)](https://www.statslab.cam.ac.uk/~rrw1/oc/ocgittins.pdf)
- [The 37% rule (dating) — Big Think](https://bigthink.com/neuropsych/the-37-percent-rule/)
- [Apartment hunting and optimal stopping — Medium/Operations Research Bit](https://medium.com/operations-research-bit/the-application-of-optimal-stopping-theory-for-finding-a-rental-apartment-6de84e7ae0b7)
